# Cartpole

 Uses a DQN agent to solve the cartpole problem in gym. 

<p align="center">
<img src="https://github.com/ankonzoid/L6_exercises/blob/master/reinforcement-learning/deep/cartpole/cartpole.gif" width="45%">
</p>

The observation vector is of dimension 4, and the action space is of dimension 2 (push cart left or right).

### Usage

Run:

> python3 cartpole.py

### Output

```
[episode 0/1000] total reward: 11, epsilon: 1.0
[episode 1/1000] total reward: 12, epsilon: 1.0
[episode 2/1000] total reward: 28, epsilon: 1.0
[episode 3/1000] total reward: 10, epsilon: 0.99
[episode 4/1000] total reward: 17, epsilon: 0.99
[episode 5/1000] total reward: 45, epsilon: 0.99

...
...
...

[episode 994/1000] total reward: 499, epsilon: 0.01
[episode 995/1000] total reward: 499, epsilon: 0.01
[episode 996/1000] total reward: 499, epsilon: 0.01
[episode 997/1000] total reward: 499, epsilon: 0.01
[episode 998/1000] total reward: 499, epsilon: 0.01
[episode 999/1000] total reward: 499, epsilon: 0.01
```
